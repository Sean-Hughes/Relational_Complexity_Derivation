dplyr::summarize(rel_train_perc_acc = round(sum(accuracy)/n(), 3)*100) %>%
dplyr::mutate(rel_train_mastery = ifelse(rel_train_perc_acc >= 90, "pass", "fail"))  # 87.5 is 36/40 correct
########################################################################
# relational testing
# select relevant data, % accuracy and pass/fail mastery criterion
rel_test_perc_acc_df <-
cleaned_df %>%
dplyr::filter(grepl("Relational_Testing_Phase", block_name)) %>%  # filter rows where the block_name includes string
dplyr::select(participant, accuracy) %>%
dplyr::group_by(participant) %>%
dplyr::summarize(rel_test_perc_acc = round(sum(accuracy)/n(), 3)*100) %>%  # % accuracy
dplyr::mutate(rel_test_mastery = ifelse(rel_test_perc_acc >= 87.5, "pass", "fail"))  # 87.5 is 7/8 correct
########################################################################
# derivation opportunities
# select relevant data
deriv_opps_df <-
cleaned_df %>%
dplyr::filter(grepl("Derivation_Opportunities", block_name)) %>%  # filter rows where the block_name includes string
dplyr::select(participant, rt, accuracy) %>%
dplyr::filter(rt <= 10000)  # rts less than 10,000 ms only
# mean rt
deriv_opps_mean_rt_df <-
deriv_opps_df %>%
dplyr::group_by(participant) %>%
dplyr::summarize(deriv_opps_rt_mean = mean(rt)) %>%
dplyr::mutate(deriv_opps_rt_mean = round(deriv_opps_rt_mean, 0))  # rounding for output simplicity is done only after D1 score calculation
# % acc
deriv_opps_perc_acc_df <-
deriv_opps_df %>%
dplyr::group_by(participant) %>%
dplyr::summarize(deriv_opps_perc_acc = round(sum(accuracy)/n(), 2)*100)
########################################################################
# IAT Test D1 scores (following Greenwald et al., 2003), % accuracy and mean latency
# select relevant data
IAT_test_df <-
cleaned_df %>%
dplyr::filter(grepl("IAT_test_", block_name),  # IAT Test only and test blocks only
rt <= 10000)  # rts less than 10,000 only
# D1 and mean rt
IAT_test_D1_and_mean_rt_df <-
IAT_test_df %>%
dplyr::group_by(participant) %>%
dplyr::summarize(IAT_test_rt_mean_compatible = mean(rt[block_name == "IAT_test_compatible_block"], na.rm = TRUE),
IAT_test_rt_mean_incompatible = mean(rt[block_name == "IAT_test_incompatible_block"], na.rm = TRUE),
IAT_test_rt_mean = mean(rt),
IAT_test_rt_sd = sd(rt)) %>%
dplyr::mutate(diff = IAT_test_rt_mean_incompatible - IAT_test_rt_mean_compatible, # this is effectively a rowwise() calculation as we have group_by() participant and then summarize()'d. rowwise() not included for brevity.
IAT_test_D1 = round(diff / IAT_test_rt_sd, 3),
IAT_test_rt_mean = round(IAT_test_rt_mean, 0)) %>%  # rounding for output simplicity is done only after D1 score calculation
dplyr::select(participant,
IAT_test_D1,
IAT_test_rt_mean)
# calculate % acc and % fast trials from test block data
IAT_test_df$too_fast_trial <- ifelse(IAT_test_df$rt < 300, 1, 0)  # add new column that records if RT < 300ms.
IAT_test_perc_acc_fast_trials_df <-
IAT_test_df %>%
dplyr::group_by(participant) %>%
dplyr::summarize(IAT_test_perc_acc = round(sum(accuracy)/n(), 2),
IAT_test_percent_fast_trials = sum(too_fast_trial)/n()) %>%  # arbitrary number of test block trials
dplyr::mutate(IAT_test_exclude_based_on_fast_trials = ifelse(IAT_test_percent_fast_trials < 0.1, "pass", "fail")) %>%
dplyr::select(participant,
IAT_test_perc_acc,
IAT_test_exclude_based_on_fast_trials)
########################################################################
# Join data frames and assess exclusion criteria
# join dfs
output_df <-
plyr::join_all(list(as.data.frame(demographics_df),  # join_all throws a requires input be data.frame error, despite is.data.frame returning TRUE for all members of list. Workaround is to coerce all to DF here.
as.data.frame(rel_train_n_blocks_df),
as.data.frame(rel_train_perc_acc_df),
as.data.frame(rel_test_perc_acc_df),
as.data.frame(deriv_opps_mean_rt_df),
as.data.frame(deriv_opps_perc_acc_df),
as.data.frame(IAT_test_D1_and_mean_rt_df),
as.data.frame(IAT_test_perc_acc_fast_trials_df)),
by = "participant",
type = "full")
# define IAT outliers (+/- 2.5 SD on lat or acc)
IAT_outlier_cutoffs_df <-
output_df %>%
dplyr::summarize(accuracy_upper = mean(IAT_test_perc_acc, na.rm = TRUE) + (2.5 * sd(IAT_test_perc_acc, na.rm = TRUE)),
accuracy_lower = mean(IAT_test_perc_acc, na.rm = TRUE) - (2.5 * sd(IAT_test_perc_acc, na.rm = TRUE)),
latency_upper = mean(IAT_test_rt_mean, na.rm = TRUE) + (2.5 * sd(IAT_test_rt_mean, na.rm = TRUE)),
latency_lower = mean(IAT_test_rt_mean, na.rm = TRUE) - (2.5 * sd(IAT_test_rt_mean, na.rm = TRUE)))
# define IAT outliers (add to output_df)
output_df <-
output_df %>%
dplyr::mutate(IAT_outlier = ifelse(IAT_test_perc_acc > IAT_outlier_cutoffs_df$accuracy_upper, TRUE,
ifelse(IAT_test_perc_acc < IAT_outlier_cutoffs_df$accuracy_lower, TRUE,
ifelse(IAT_test_rt_mean > IAT_outlier_cutoffs_df$latency_upper, TRUE,
ifelse(IAT_test_rt_mean < IAT_outlier_cutoffs_df$latency_lower, TRUE, FALSE)))))
# Assess if each participant meet any of the four exclusion criteria. Also excludes participants with partial data.
output_df <-
output_df %>%
rowwise() %>%
dplyr::mutate(exclude = ifelse(rel_train_mastery == "fail", TRUE,
ifelse(rel_test_mastery == "fail", TRUE,
ifelse(IAT_test_exclude_based_on_fast_trials == "fail", TRUE,
ifelse(IAT_outlier == TRUE, TRUE,
FALSE)))))
########################################################################
# Write to disk
write.csv(output_df, file = "~/Git/Derivation study/Data processing/processed data for analysis.csv", row.names=FALSE)
rm(list=ls())
###################################################################
# dependencies
library(tidyr)
library(dplyr)
library(psych)
###################################################################
# data acquisition
setwd("~/Git/Derivation study/Analyses/")
data_df <- read.csv("~/Git/Derivation study/Data processing/processed data for analysis.csv")
plot(density(data_df$IAT_test_D1[data_df$condition == "low"]))
lines(density(data_df$IAT_test_D1[data_df$condition == "high"]))
plot(density(data_df$deriv_opps_rt_mean[data_df$condition == "low"]))
lines(density(data_df$deriv_opps_rt_mean[data_df$condition == "high"]))
plot(density(data_df$IAT_test_D1[data_df$condition == "low"]))
lines(density(data_df$IAT_test_D1[data_df$condition == "high"]))
plot(density(data_df$deriv_opps_rt_mean[data_df$condition == "low"]))
lines(density(data_df$deriv_opps_rt_mean[data_df$condition == "high"]))
gender_counts                 <- data_df %>% count(gender)
rel_train_criterion_counts    <- data_df %>% count(rel_train_mastery)
rel_test_criterion_counts     <- data_df %>% count(rel_test_mastery)
IAT_test_criterion_counts     <- data_df %>% count(IAT_test_exclude_based_on_fast_trials)
total_exclusions_count        <- data_df %>% count(exclude)
# all ps
descriptives_all_participants <-
data_df %>%
dplyr::select(age,
rel_train_n_blocks,
rel_train_perc_acc,
rel_test_perc_acc,
IAT_test_rt_mean,
IAT_test_perc_acc,
deriv_opps_rt_mean,
deriv_opps_perc_acc) %>%
psych::describe(fast = TRUE,  # subset of descriptive stats
ranges = FALSE,
trim = 0) %>%
dplyr::select(-vars, -se)
# by condition
descriptives_by_condition <-
data_df %>%
dplyr::select(age,
rel_train_n_blocks,
rel_train_perc_acc,
rel_test_perc_acc,
IAT_test_rt_mean,
IAT_test_perc_acc,
deriv_opps_rt_mean,
deriv_opps_perc_acc) %>%
psych::describeBy(data_df$condition,
fast = TRUE,  # subset of descriptive stats
ranges = FALSE,
trim = 0)
###################################################################
# write output to disk
sink("descriptive statistics.txt")
cat("\n Gender counts \n")
gender_counts
cat("\n relational training pass/fails \n")
rel_train_criterion_counts
cat("\n relational testing pass/fails \n")
rel_test_criterion_counts
cat("\n IAT test criterion pass/fails \n")
IAT_test_criterion_counts
cat("\n total exclusions \n")
total_exclusions_count
cat("\n")
descriptives_all_participants
cat("\n")
descriptives_by_condition
sink()
rm(list=ls())
########################################################################
## Dependencies
library(BEST)
library(dplyr)
library(reshape2)
########################################################################
# Specific data, variables, and parameters of test
# labels
DV_name                 <- "mean RTs in the derivation opportunities task"
condition_a_name        <- "the low condition"
condition_b_name        <- "the high condition"
analysis_file_name      <- "BEST - deriv opps RTs.RData"
output_file_name        <- "BEST output - deriv opps RTs.txt"
ROPE                    <- c(-0.2, 0.2)  # region of practical equivalence (ROPE) for assessing group equality.
# working directory where output will be saved
setwd("~/Git/Derivation study/Analyses/")
# Data acquisition
data_df <-
read.csv("~/Git/Derivation study/Data processing/processed data for analysis.csv") %>%
filter(exclude == FALSE)  # exclude participants who met any of the three mastery criteria
# BEST test
attach(data_df)  # use the input data frame for all tests below
View(data_df)
View(data_df)
BEST <- BESTmcmc(change_score[condition == "low"],  # SET THE DV AND CONDITION NAMES HERE
change_score[condition == "high"],  # SET THE DV AND CONDITION NAMES HERE
burnInSteps = 1000,  # Increase this if convergence is insufficient
numSavedSteps = 1e+05,  # Increase this or thinsteps if effective sample size is insufficient
thinSteps = 1)
View(data_df)
View(data_df)
BEST <- BESTmcmc(IAT_test_D1[condition == "low"],  # SET THE DV AND CONDITION NAMES HERE
IAT_test_D1[condition == "high"],  # SET THE DV AND CONDITION NAMES HERE
burnInSteps = 1000,  # Increase this if convergence is insufficient
numSavedSteps = 1e+05,  # Increase this or thinsteps if effective sample size is insufficient
thinSteps = 1)
BEST_output_df <-
summary(BEST, ROPEeff = ROPE) %>%
as.data.frame() %>%  # convert to data frame for easier subsetting
tibble::rownames_to_column() %>%  # convert rowname to column for subsetting
dplyr::mutate(mode = round(mode, 2),  # round values and rename
HDIlo = round(HDIlo, 2),
HDIup = round(HDIup, 2),
percent_greater_than_zero = round(`%>compVal`, 2),
percent_in_rope = round(`%InROPE`, 2)) %>%
dplyr::select(-`%InROPE`, -`%>compVal`)
n_eff_strings <-
capture.output(print(BEST)) %>%  # capture print as variable
as.data.frame() %>%  # convert to data frame for easier subsetting
tibble::rownames_to_column() %>%
dplyr::filter(rowname > 3) %>%  # trim top and bottom rows
dplyr::filter(rowname <= 8) %>%
dplyr::select(-rowname)
colnames(n_eff_strings) <- "strings"
MCMC_checks <-
reshape2::colsplit(string = n_eff_strings$strings,
pattern = "\\s+",  # treat one or more spaces as a column break (uses regular expressions)
names = c("parameter", "mean", "sd", "median", "HDIlo", "HDIup", "Rhat", "n.eff")) %>%
dplyr::select(parameter, Rhat, n.eff) %>%
dplyr::mutate(Rhat_sufficient = ifelse(Rhat > 1.05, 0, 1),  # insufficient convergence if less than value
n_eff_sufficient = ifelse(n.eff <= 10000, 0, 1)) %>%  # insufficient effective sample size if less than value
dplyr::summarize(Rhat_sufficient = as.logical(min(Rhat_sufficient)),
n_eff_sufficient = as.logical(min(n_eff_sufficient)))
if(is.na(MCMC_checks[1,1]) | is.na(MCMC_checks[1,2])) print("************** \n ERROR: the console width is to narrow to print the results correctly! \n **************")
MCMC_checks <-
reshape2::colsplit(string = n_eff_strings$strings,
pattern = "\\s+",  # treat one or more spaces as a column break (uses regular expressions)
names = c("parameter", "mean", "sd", "median", "HDIlo", "HDIup", "Rhat", "n.eff")) %>%
dplyr::select(parameter, Rhat, n.eff) %>%
dplyr::mutate(Rhat_sufficient = ifelse(Rhat > 1.05, 0, 1),  # insufficient convergence if less than value
n_eff_sufficient = ifelse(n.eff <= 10000, 0, 1)) %>%  # insufficient effective sample size if less than value
dplyr::summarize(Rhat_sufficient = as.logical(min(Rhat_sufficient)),
n_eff_sufficient = as.logical(min(n_eff_sufficient)))
if(is.na(MCMC_checks[1,1]) | is.na(MCMC_checks[1,2])) print("************** \n ERROR: the console width is to narrow to print the results correctly! \n **************")
MCMC_checks <-
reshape2::colsplit(string = n_eff_strings$strings,
pattern = "\\s+",  # treat one or more spaces as a column break (uses regular expressions)
names = c("parameter", "mean", "sd", "median", "HDIlo", "HDIup", "Rhat", "n.eff")) %>%
dplyr::select(parameter, Rhat, n.eff) %>%
dplyr::mutate(Rhat_sufficient = ifelse(Rhat > 1.05, 0, 1),  # insufficient convergence if less than value
n_eff_sufficient = ifelse(n.eff <= 10000, 0, 1)) %>%  # insufficient effective sample size if less than value
dplyr::summarize(Rhat_sufficient = as.logical(min(Rhat_sufficient)),
n_eff_sufficient = as.logical(min(n_eff_sufficient)))
if(is.na(MCMC_checks[1,1]) | is.na(MCMC_checks[1,2])) print("************** \n ERROR: the console width is to narrow to print the results correctly! \n **************")
MCMC_checks <-
reshape2::colsplit(string = n_eff_strings$strings,
pattern = "\\s+",  # treat one or more spaces as a column break (uses regular expressions)
names = c("parameter", "mean", "sd", "median", "HDIlo", "HDIup", "Rhat", "n.eff")) %>%
dplyr::select(parameter, Rhat, n.eff) %>%
dplyr::mutate(Rhat_sufficient = ifelse(Rhat > 1.05, 0, 1),  # insufficient convergence if less than value
n_eff_sufficient = ifelse(n.eff <= 10000, 0, 1)) %>%  # insufficient effective sample size if less than value
dplyr::summarize(Rhat_sufficient = as.logical(min(Rhat_sufficient)),
n_eff_sufficient = as.logical(min(n_eff_sufficient)))
if(is.na(MCMC_checks[1,1]) | is.na(MCMC_checks[1,2])) print("************** \n ERROR: the console width is to narrow to print the results correctly! \n **************")
########################################################################
n_eff_strings <-
capture.output(print(BEST)) %>%  # capture print as variable
as.data.frame() %>%  # convert to data frame for easier subsetting
tibble::rownames_to_column() %>%
dplyr::filter(rowname > 3) %>%  # trim top and bottom rows
dplyr::filter(rowname <= 8) %>%
dplyr::select(-rowname)
colnames(n_eff_strings) <- "strings"
MCMC_checks <-
reshape2::colsplit(string = n_eff_strings$strings,
pattern = "\\s+",  # treat one or more spaces as a column break (uses regular expressions)
names = c("parameter", "mean", "sd", "median", "HDIlo", "HDIup", "Rhat", "n.eff")) %>%
dplyr::select(parameter, Rhat, n.eff) %>%
dplyr::mutate(Rhat_sufficient = ifelse(Rhat > 1.05, 0, 1),  # insufficient convergence if less than value
n_eff_sufficient = ifelse(n.eff <= 10000, 0, 1)) %>%  # insufficient effective sample size if less than value
dplyr::summarize(Rhat_sufficient = as.logical(min(Rhat_sufficient)),
n_eff_sufficient = as.logical(min(n_eff_sufficient)))
if(is.na(MCMC_checks[1,1]) | is.na(MCMC_checks[1,2])) print("************** \n ERROR: the console width is to narrow to print the results correctly! \n **************")
########################################################################
# View results
# full output
BEST_output_df
# plot
plotAll(BEST, ROPEeff = ROPE, showCurve = TRUE)
########################################################################
## extract individual variables for easier printing
MCMC_convergence        <- MCMC_checks$Rhat_sufficient
MCMC_effective_n        <- MCMC_checks$n_eff_sufficient
es_mode                 <- BEST_output_df %>% filter(rowname == "effSz") %>% .$mode
es_hdi_low              <- BEST_output_df %>% filter(rowname == "effSz") %>% .$HDIlo
es_hdi_high             <- BEST_output_df %>% filter(rowname == "effSz") %>% .$HDIup
es_in_rope              <- BEST_output_df %>% filter(rowname == "effSz") %>% .$percent_in_rope
m_condition_a           <- BEST_output_df %>% filter(rowname == "mu1") %>% .$mean
m_condition_a           <- round(m_condition_a, 2)
m_condition_b           <- BEST_output_df %>% filter(rowname == "mu2") %>% .$mean
m_condition_b           <- round(m_condition_b, 2)
########################################################################
# construct strings from output
# MCMC convergence
MCMC_checks_string      <- ifelse(MCMC_convergence == FALSE,
"The MCMC chains did not converge well. NB 'burnInSteps' SHOULD BE INCREASED AND THE TEST RE-RUN.",
ifelse(MCMC_effective_n == FALSE,
"The effective sample size was insufficient for one or more parameter. NB 'numSavedSteps' OR 'thinSteps' SHOULD BE INCREASED AND THE TEST RE-RUN.",
"The MCMC chains converged well and had an effective sample size (ESS) greater than 10,000 for all parameters."))
# interpret effect size based on Cohen's (1988) guidelines
es_size                 <- ifelse(abs(es_mode) < 0.2, "negligable",
ifelse(abs(es_mode) < 0.5, "small",
ifelse(abs(es_mode) < 0.8, "medium", "large")))
# assess if >=95% of credible es are inside the ROPE
equality_boolean        <- ifelse(es_in_rope >= 95, 1, 0)
# assess if the 95% HDI includes the zero point
es_hid_includes_zero    <- ifelse((es_hdi_low * es_hdi_high) < 0,  # if the product of the number is negative then one is positive and one is negative, therefore the interval contains zero. Otherwise, it does not.
"included zero",
"did not include zero")
# Assess 3 way decision path based on equality and differences booleans to make a final conclusion
conclusions             <- ifelse(equality_boolean == 1,  # NB even if differences==1 here, effect is still so small as to consider groups equal.
"Given that more than 95% of estimated effect sizes fell within the ROPE, the posterior distribution therefore indicated that the groups were credibly equal. ",
ifelse(es_hid_includes_zero == "did not include zero",
"Given that less than 95% of estimated effect sizes fell within the ROPE and the 95% RDI did not include zero, the posterior distribution therefore indicated that credible differences existed between the groups. ",
"Although the 95% HDI included zero, less than 95% of estimated effect sizes within the ROPE. As such, the posterior distribution indicated that there was great uncertainty about the magnitude of difference between the two conditions, which were neither credibly different nor credibly equal. "))
########################################################################
# combine all output into a natural langauge string
BEST_parameters         <- sprintf("Bayesian analysis (Kruschke, 2013) was used to compare differences in %s between %s and %s. The analysis accommodated the possibility of outliers by using t distributions to describe the data, and allowed for different variances across the groups. Specifically, the model employed 5 parameters to describe the data: the means of both conditions (μ1, μ2), the standard deviations of both conditions (σ1, σ2), and a shared normality parameter (ν). We employed the default prior, which is a noncommittal prior intended to have minimal impact on the posterior distribution. Specifically, for sample yi in (y1, y2), μi = normal(M = mean(yi), SD = sd(yi)*5)), σi = gamma(Mo = sd(yi), SD = sd(yi)*5), ν = gamma(M = 30, SD = 30). The posterior distribution was represented by Markov Chain Monte Carlo (MCMC) simulation methods (see Kruschke, 2013). For decision-making purposes, a region of practical equivalence (ROPE: Kruschke, 2011) for negligible effect size was defined (-0.2 < d < 0.2; Cohen, 1988). ",
DV_name,
condition_a_name,
condition_b_name)
BEST_text               <- sprintf("%s The posterior distributions showed the modal estimate of the %s was %s for %s and %s for %s. The modal estimated effect size was %s (Cohen, 1988) with a 95%% Highest Density Interval that %s, Mo d = %s, 95%% HDI [%s, %s]. %s %% of estimated effect sizes fell within the ROPE. %s",
MCMC_checks_string,
DV_name,
m_condition_a,
condition_a_name,
m_condition_b,
condition_b_name,
es_size,
es_hid_includes_zero,
es_mode,
es_hdi_low,
es_hdi_high,
es_in_rope,
conclusions)
########################################################################
# write data to disk
sink(output_file_name)
cat(BEST_parameters)
cat("\n\n")
cat(BEST_text)
sink()
DV_name                 <- "IAT D1 scores"
condition_a_name        <- "the low condition"
condition_b_name        <- "the high condition"
analysis_file_name      <- "BEST - IAT D1.RData"
output_file_name        <- "BEST output - IAT D1.txt"
ROPE                    <- c(-0.2, 0.2)  # region of practical equivalence (ROPE) for assessing group equality.
# working directory where output will be saved
setwd("~/Git/Derivation study/Analyses/")
# Data acquisition
data_df <-
read.csv("~/Git/Derivation study/Data processing/processed data for analysis.csv") %>%
filter(exclude == FALSE)  # exclude participants who met any of the three mastery criteria
# BEST test
attach(data_df)  # use the input data frame for all tests below
BEST <- BESTmcmc(IAT_test_D1[condition == "low"],  # SET THE DV AND CONDITION NAMES HERE
IAT_test_D1[condition == "high"],  # SET THE DV AND CONDITION NAMES HERE
burnInSteps = 1000,  # Increase this if convergence is insufficient
numSavedSteps = 1e+05,  # Increase this or thinsteps if effective sample size is insufficient
thinSteps = 1)
########################################################################
# save to/read from disk
# save analysis to disk
save(BEST, file = analysis_file_name)
# Load previously saved analysis from disk
#load(file = analysis_file_name)
########################################################################
# tidy up output
BEST_output_df <-
summary(BEST, ROPEeff = ROPE) %>%
as.data.frame() %>%  # convert to data frame for easier subsetting
tibble::rownames_to_column() %>%  # convert rowname to column for subsetting
dplyr::mutate(mode = round(mode, 2),  # round values and rename
HDIlo = round(HDIlo, 2),
HDIup = round(HDIup, 2),
percent_greater_than_zero = round(`%>compVal`, 2),
percent_in_rope = round(`%InROPE`, 2)) %>%
dplyr::select(-`%InROPE`, -`%>compVal`)
########################################################################
## MCMC convergence and n.eff assessment
# convert the strings returned by print into a usable data frame. This is a bit hacky but it works.
# NB!! this is dependant on the width of the RStudio console being adequtely wide to print all columns on one row,
# even though this printing is not shown
n_eff_strings <-
capture.output(print(BEST)) %>%  # capture print as variable
as.data.frame() %>%  # convert to data frame for easier subsetting
tibble::rownames_to_column() %>%
dplyr::filter(rowname > 3) %>%  # trim top and bottom rows
dplyr::filter(rowname <= 8) %>%
dplyr::select(-rowname)
colnames(n_eff_strings) <- "strings"
MCMC_checks <-
reshape2::colsplit(string = n_eff_strings$strings,
pattern = "\\s+",  # treat one or more spaces as a column break (uses regular expressions)
names = c("parameter", "mean", "sd", "median", "HDIlo", "HDIup", "Rhat", "n.eff")) %>%
dplyr::select(parameter, Rhat, n.eff) %>%
dplyr::mutate(Rhat_sufficient = ifelse(Rhat > 1.05, 0, 1),  # insufficient convergence if less than value
n_eff_sufficient = ifelse(n.eff <= 10000, 0, 1)) %>%  # insufficient effective sample size if less than value
dplyr::summarize(Rhat_sufficient = as.logical(min(Rhat_sufficient)),
n_eff_sufficient = as.logical(min(n_eff_sufficient)))
########################################################################
if(is.na(MCMC_checks[1,1]) | is.na(MCMC_checks[1,2])) print("************** \n ERROR: the console width is to narrow to print the results correctly! \n **************")
# full output
# View results
BEST_output_df
# plot
plotAll(BEST, ROPEeff = ROPE, showCurve = TRUE)
########################################################################
## extract individual variables for easier printing
MCMC_convergence        <- MCMC_checks$Rhat_sufficient
MCMC_effective_n        <- MCMC_checks$n_eff_sufficient
es_mode                 <- BEST_output_df %>% filter(rowname == "effSz") %>% .$mode
es_hdi_low              <- BEST_output_df %>% filter(rowname == "effSz") %>% .$HDIlo
es_hdi_high             <- BEST_output_df %>% filter(rowname == "effSz") %>% .$HDIup
es_in_rope              <- BEST_output_df %>% filter(rowname == "effSz") %>% .$percent_in_rope
m_condition_a           <- BEST_output_df %>% filter(rowname == "mu1") %>% .$mean
m_condition_a           <- round(m_condition_a, 2)
m_condition_b           <- BEST_output_df %>% filter(rowname == "mu2") %>% .$mean
m_condition_b           <- round(m_condition_b, 2)
########################################################################
# construct strings from output
# MCMC convergence
MCMC_checks_string      <- ifelse(MCMC_convergence == FALSE,
"The MCMC chains did not converge well. NB 'burnInSteps' SHOULD BE INCREASED AND THE TEST RE-RUN.",
ifelse(MCMC_effective_n == FALSE,
"The effective sample size was insufficient for one or more parameter. NB 'numSavedSteps' OR 'thinSteps' SHOULD BE INCREASED AND THE TEST RE-RUN.",
"The MCMC chains converged well and had an effective sample size (ESS) greater than 10,000 for all parameters."))
# interpret effect size based on Cohen's (1988) guidelines
es_size                 <- ifelse(abs(es_mode) < 0.2, "negligable",
ifelse(abs(es_mode) < 0.5, "small",
ifelse(abs(es_mode) < 0.8, "medium", "large")))
# assess if >=95% of credible es are inside the ROPE
equality_boolean        <- ifelse(es_in_rope >= 95, 1, 0)
# assess if the 95% HDI includes the zero point
"included zero",
es_hid_includes_zero    <- ifelse((es_hdi_low * es_hdi_high) < 0,  # if the product of the number is negative then one is positive and one is negative, therefore the interval contains zero. Otherwise, it does not.
"did not include zero")
# Assess 3 way decision path based on equality and differences booleans to make a final conclusion
conclusions             <- ifelse(equality_boolean == 1,  # NB even if differences==1 here, effect is still so small as to consider groups equal.
"Given that more than 95% of estimated effect sizes fell within the ROPE, the posterior distribution therefore indicated that the groups were credibly equal. ",
ifelse(es_hid_includes_zero == "did not include zero",
"Given that less than 95% of estimated effect sizes fell within the ROPE and the 95% RDI did not include zero, the posterior distribution therefore indicated that credible differences existed between the groups. ",
########################################################################
"Although the 95% HDI included zero, less than 95% of estimated effect sizes within the ROPE. As such, the posterior distribution indicated that there was great uncertainty about the magnitude of difference between the two conditions, which were neither credibly different nor credibly equal. "))
# combine all output into a natural langauge string
BEST_parameters         <- sprintf("Bayesian analysis (Kruschke, 2013) was used to compare differences in %s between %s and %s. The analysis accommodated the possibility of outliers by using t distributions to describe the data, and allowed for different variances across the groups. Specifically, the model employed 5 parameters to describe the data: the means of both conditions (μ1, μ2), the standard deviations of both conditions (σ1, σ2), and a shared normality parameter (ν). We employed the default prior, which is a noncommittal prior intended to have minimal impact on the posterior distribution. Specifically, for sample yi in (y1, y2), μi = normal(M = mean(yi), SD = sd(yi)*5)), σi = gamma(Mo = sd(yi), SD = sd(yi)*5), ν = gamma(M = 30, SD = 30). The posterior distribution was represented by Markov Chain Monte Carlo (MCMC) simulation methods (see Kruschke, 2013). For decision-making purposes, a region of practical equivalence (ROPE: Kruschke, 2011) for negligible effect size was defined (-0.2 < d < 0.2; Cohen, 1988). ",
DV_name,
condition_a_name,
condition_b_name)
BEST_text               <- sprintf("%s The posterior distributions showed the modal estimate of the %s was %s for %s and %s for %s. The modal estimated effect size was %s (Cohen, 1988) with a 95%% Highest Density Interval that %s, Mo d = %s, 95%% HDI [%s, %s]. %s %% of estimated effect sizes fell within the ROPE. %s",
MCMC_checks_string,
DV_name,
m_condition_a,
condition_a_name,
m_condition_b,
condition_b_name,
es_size,
es_hid_includes_zero,
es_mode,
es_hdi_low,
es_hdi_high,
es_in_rope,
conclusions)
########################################################################
# write data to disk
sink(output_file_name)
cat(BEST_parameters)
cat("\n\n")
cat(BEST_text)
sink()
rm(list=ls())
########################################################################
# dependencies
library(dplyr)
library(effsize)
library(weights)  # for rd(), a round() alternative
########################################################################
# Specific data, variables, and parameters of test
# labels
DV_name                   <- "mean RT on the derivation opportunities task"
condition_a_name          <- "the low condition"
condition_b_name          <- "the high condition"
condition_a_code_in_data  <- 1
condition_b_code_in_data  <- 2
output_file_name          <- "t test output - derivation opportunities mean RT.txt"
# data acquisition
setwd("~/Git/Derivation study/Analyses/")
# Data acquisition
data_df <-
read.csv("~/Git/Derivation study/Data processing/processed data for analysis.csv") %>%
filter(exclude == FALSE)  # exclude participants who met any of the three mastery criteria
attach(data_df)  # use the input data frame for all tests below
# t test
t_test <- t.test(formula = deriv_opps_rt_mean ~ condition,    # IV ~ DV adjusted here
alternative = "two.sided",
paired = FALSE)
